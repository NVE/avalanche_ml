{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from avaml.aggregatedata import ForecastDataset, LabeledData, CsvMissingError\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from avaml.machine.sk_clustered import SKClusteringMachine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv\n"
     ]
    }
   ],
   "source": [
    "model_prefix = ''\n",
    "days = 2\n",
    "regobs_types = [\n",
    "    \"Faretegn\",\n",
    "    \"Tester\",\n",
    "    \"Skredaktivitet\",\n",
    "    \"Skredhendelse\",\n",
    "    \"Sn√∏dekke\",\n",
    "    \"Skredproblem\",\n",
    "    \"Skredfarevurdering\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"Reading csv\")\n",
    "    labeled_data = LabeledData.from_csv(days=days, regobs_types=regobs_types, with_varsom=True)\n",
    "except CsvMissingError:\n",
    "    print(\"Csv missing. Fetching online data. (This takes a long time.)\")\n",
    "    labeled_data = ForecastDataset(regobs_types=regobs_types).label(days=days, with_varsom=True)\n",
    "    labeled_data.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = labeled_data.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold: 0\n",
      "Testing fold: 0\n",
      "Training fold: 1\n",
      "Testing fold: 1\n",
      "Training fold: 2\n",
      "Testing fold: 2\n",
      "Training fold: 3\n",
      "Testing fold: 3\n",
      "Training fold: 4\n",
      "Testing fold: 4\n"
     ]
    }
   ],
   "source": [
    "f1 = None\n",
    "importances = None\n",
    "strat = (\"CLASS\", \"\", \"danger_level\")\n",
    "for split_idx, (training_data, testing_data) in enumerate(labeled_data.kfold(5, stratify=strat)):\n",
    "    print(f\"Training fold: {split_idx}\")\n",
    "    dt = DecisionTreeClassifier(max_depth=7, class_weight={\"1\": 1, \"2\": 1, \"3\": 1, \"4\": 1})\n",
    "    clustering = AgglomerativeClustering(n_clusters=20)\n",
    "\n",
    "    bm = SKClusteringMachine(dt, clustering)\n",
    "    bm.fit(training_data)\n",
    "\n",
    "    bm.dump(model_prefix)\n",
    "    ubm = SKClusteringMachine.load(model_prefix)\n",
    "\n",
    "    print(f\"Testing fold: {split_idx}\")\n",
    "    predicted_data = ubm.predict(testing_data)\n",
    "    labeled_data.pred.loc[predicted_data.pred.index] = predicted_data.pred\n",
    "    split_imp = ubm.feature_importances()\n",
    "    importances = split_imp if importances is None else importances + (split_imp - importances) / (split_idx + 1)\n",
    "    f1_series = predicted_data.f1()\n",
    "    f1 = f1_series if f1 is None else f1 + (f1_series - f1) / (split_idx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions\n",
      "Writing importances\n",
      "Writing F1 scores\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing predictions\")\n",
    "predicted_data.pred.to_csv(\"output/{0}_sk-cluster_pred.csv\".format(model_prefix), sep=';')\n",
    "\n",
    "print(\"Writing importances\")\n",
    "importances.to_csv(\"output/{0}_sk-cluster_importances.csv\".format(model_prefix), sep=';')\n",
    "\n",
    "print(\"Writing F1 scores\")\n",
    "f1.to_csv(\"output/{0}_sk-cluster_f1.csv\".format(model_prefix), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing decision tree visualisation\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing decision tree visualisation\")\n",
    "dt = DecisionTreeClassifier(max_depth=7, class_weight={\"1\": 1, \"2\": 1, \"3\": 1, \"4\": 1})\n",
    "clustering = AgglomerativeClustering(n_clusters=20)\n",
    "bm = SKClusteringMachine(dt, clustering)\n",
    "bm.fit(labeled_data)\n",
    "bm.dt_pdf(\"output/{0}_sk-cluster_dt\".format(model_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
